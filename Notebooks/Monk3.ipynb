{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Monk3\n",
    "Grid Search for Monk1 dataset model selection\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "76221a5d468b33a8"
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "from exclusiveAI.components.Validation.HoldOut import parallel_hold_out, hold_out\n",
    "from exclusiveAI.components.Validation.KFoldCrossValidation import validate\n",
    "from exclusiveAI.ConfiguratorGen import ConfiguratorGen\n",
    "from exclusiveAI.datasets.monk import read_monk3\n",
    "from exclusiveAI.utils import one_hot_encoding\n",
    "from exclusiveAI.Composer import Composer\n",
    "from exclusiveAI.components.CallBacks import EarlyStoppingCallback\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from exclusiveAI.utils import plot_history\n",
    "import os, json"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-08T14:06:08.932269Z",
     "start_time": "2024-01-08T14:06:08.889045Z"
    }
   },
   "id": "d8f565beeebe055d"
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Read Monk3 dataset "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "41c193fe85cb2214"
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "training_data, training_labels, test_data, test_labels = read_monk3(\"../exclusiveAI/datasets/\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-08T14:06:08.970481Z",
     "start_time": "2024-01-08T14:06:08.946106Z"
    }
   },
   "id": "c2efbf06487c3d0f"
  },
  {
   "cell_type": "markdown",
   "source": [
    "One-Hot Encoding Training Dataset"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6c2a7c15dc5f0bf3"
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "training_data = one_hot_encoding(training_data)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-08T14:06:08.970819Z",
     "start_time": "2024-01-08T14:06:08.954591Z"
    }
   },
   "id": "b54f54f940a1597f"
  },
  {
   "cell_type": "markdown",
   "source": [
    "One-Hot Encoding Test Dataset"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2fe910ec3314ef77"
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "test_data = one_hot_encoding(test_data)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-08T14:06:08.986969Z",
     "start_time": "2024-01-08T14:06:08.968784Z"
    }
   },
   "id": "7d7ff08be1ee7aa5"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Getting the (most interesting) models from the big grid search "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2a26c81a871bfa64"
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "8136eab7cdd2194d"
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Appending: 100%|██████████| 540/540 [00:00<00:00, 6778.04it/s]\n",
      "Appending: 100%|██████████| 19440/19440 [00:00<00:00, 204251.17it/s]\n",
      "Models:   1%|\u001B[37m          \u001B[0m| 173/19440 [00:13<24:11, 13.28it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[22], line 42\u001B[0m\n\u001B[1;32m     39\u001B[0m configs\u001B[38;5;241m=\u001B[39m[]\n\u001B[1;32m     40\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;18m__name__\u001B[39m \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m__main__\u001B[39m\u001B[38;5;124m'\u001B[39m:\n\u001B[1;32m     41\u001B[0m     configs\u001B[38;5;241m.\u001B[39mappend(\n\u001B[0;32m---> 42\u001B[0m         \u001B[43mparallel_hold_out\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmyConfigurator\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtraining\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtraining_data\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtraining_target\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtraining_labels\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mepochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mepochs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     43\u001B[0m \u001B[43m                          \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbatch_size\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnum_models\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m100\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mworkers\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m4\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnumber_of_initializations\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m3\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mreturn_models_history\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m     44\u001B[0m \u001B[43m                          \u001B[49m\u001B[43m)\u001B[49m)\n\u001B[1;32m     46\u001B[0m     configs \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mDataFrame(configs)\n\u001B[1;32m     47\u001B[0m     \u001B[38;5;66;03m# Save as json\u001B[39;00m\n",
      "File \u001B[0;32m~/Documents/Projects/MLProject/exclusiveAI/components/Validation/HoldOut.py:106\u001B[0m, in \u001B[0;36mparallel_hold_out\u001B[0;34m(configs, training, training_target, metric, num_models, regression, number_of_initializations, epochs, batch_size, return_models_history, disable_line, workers, assessment)\u001B[0m\n\u001B[1;32m    103\u001B[0m evaluator \u001B[38;5;241m=\u001B[39m ProcessPoolExecutor(max_workers\u001B[38;5;241m=\u001B[39mworkers) \u001B[38;5;28;01mif\u001B[39;00m workers \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mor\u001B[39;00m workers \u001B[38;5;241m!=\u001B[39m \u001B[38;5;241m1\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    104\u001B[0m results_func \u001B[38;5;241m=\u001B[39m evaluator\u001B[38;5;241m.\u001B[39mmap \u001B[38;5;28;01mif\u001B[39;00m evaluator \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28mmap\u001B[39m\n\u001B[0;32m--> 106\u001B[0m results \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mlist\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mtqdm\u001B[49m\u001B[43m(\u001B[49m\u001B[43mresults_func\u001B[49m\u001B[43m(\u001B[49m\u001B[43mevaluate_partial\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mconfigs\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtotal\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mlen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mconfigs\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdesc\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mModels\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcolour\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mwhite\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    108\u001B[0m \u001B[38;5;66;03m# results = Parallel(n_jobs=workers)(\u001B[39;00m\n\u001B[1;32m    109\u001B[0m \u001B[38;5;66;03m#     delayed(evaluate_model)(config, train.copy(), train_target.copy(),\u001B[39;00m\n\u001B[1;32m    110\u001B[0m \u001B[38;5;66;03m#                             validation=None if assessment else validation.copy(),\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    116\u001B[0m \u001B[38;5;66;03m#     for config in tqdm(configs, desc=\"Models\", colour=\"white\")\u001B[39;00m\n\u001B[1;32m    117\u001B[0m \u001B[38;5;66;03m# )\u001B[39;00m\n\u001B[1;32m    118\u001B[0m best_models, best_configs \u001B[38;5;241m=\u001B[39m get_best_model(results, num_models)\n",
      "File \u001B[0;32m~/Documents/Projects/MLProject/exclusiveAIvenv/lib/python3.12/site-packages/tqdm/std.py:1182\u001B[0m, in \u001B[0;36mtqdm.__iter__\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m   1179\u001B[0m time \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_time\n\u001B[1;32m   1181\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m-> 1182\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mobj\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43miterable\u001B[49m\u001B[43m:\u001B[49m\n\u001B[1;32m   1183\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43;01myield\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mobj\u001B[49m\n\u001B[1;32m   1184\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;66;43;03m# Update and possibly print the progressbar.\u001B[39;49;00m\n\u001B[1;32m   1185\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;66;43;03m# Note: does not call self.update(1) for speed optimisation.\u001B[39;49;00m\n",
      "File \u001B[0;32m~/miniconda3/envs/exclusiveAI/lib/python3.12/concurrent/futures/process.py:608\u001B[0m, in \u001B[0;36m_chain_from_iterable_of_lists\u001B[0;34m(iterable)\u001B[0m\n\u001B[1;32m    602\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_chain_from_iterable_of_lists\u001B[39m(iterable):\n\u001B[1;32m    603\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    604\u001B[0m \u001B[38;5;124;03m    Specialized implementation of itertools.chain.from_iterable.\u001B[39;00m\n\u001B[1;32m    605\u001B[0m \u001B[38;5;124;03m    Each item in *iterable* should be a list.  This function is\u001B[39;00m\n\u001B[1;32m    606\u001B[0m \u001B[38;5;124;03m    careful not to keep references to yielded objects.\u001B[39;00m\n\u001B[1;32m    607\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m--> 608\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43melement\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43miterable\u001B[49m\u001B[43m:\u001B[49m\n\u001B[1;32m    609\u001B[0m \u001B[43m        \u001B[49m\u001B[43melement\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mreverse\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    610\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43;01mwhile\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43melement\u001B[49m\u001B[43m:\u001B[49m\n",
      "File \u001B[0;32m~/miniconda3/envs/exclusiveAI/lib/python3.12/concurrent/futures/_base.py:619\u001B[0m, in \u001B[0;36mExecutor.map.<locals>.result_iterator\u001B[0;34m()\u001B[0m\n\u001B[1;32m    616\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m fs:\n\u001B[1;32m    617\u001B[0m     \u001B[38;5;66;03m# Careful not to keep a reference to the popped future\u001B[39;00m\n\u001B[1;32m    618\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m timeout \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m--> 619\u001B[0m         \u001B[38;5;28;01myield\u001B[39;00m \u001B[43m_result_or_cancel\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfs\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpop\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    620\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    621\u001B[0m         \u001B[38;5;28;01myield\u001B[39;00m _result_or_cancel(fs\u001B[38;5;241m.\u001B[39mpop(), end_time \u001B[38;5;241m-\u001B[39m time\u001B[38;5;241m.\u001B[39mmonotonic())\n",
      "File \u001B[0;32m~/miniconda3/envs/exclusiveAI/lib/python3.12/concurrent/futures/_base.py:317\u001B[0m, in \u001B[0;36m_result_or_cancel\u001B[0;34m(***failed resolving arguments***)\u001B[0m\n\u001B[1;32m    315\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m    316\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 317\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfut\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mresult\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtimeout\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    318\u001B[0m     \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[1;32m    319\u001B[0m         fut\u001B[38;5;241m.\u001B[39mcancel()\n",
      "File \u001B[0;32m~/miniconda3/envs/exclusiveAI/lib/python3.12/concurrent/futures/_base.py:451\u001B[0m, in \u001B[0;36mFuture.result\u001B[0;34m(self, timeout)\u001B[0m\n\u001B[1;32m    448\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_state \u001B[38;5;241m==\u001B[39m FINISHED:\n\u001B[1;32m    449\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m__get_result()\n\u001B[0;32m--> 451\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_condition\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mwait\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtimeout\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    453\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_state \u001B[38;5;129;01min\u001B[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n\u001B[1;32m    454\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m CancelledError()\n",
      "File \u001B[0;32m~/miniconda3/envs/exclusiveAI/lib/python3.12/threading.py:334\u001B[0m, in \u001B[0;36mCondition.wait\u001B[0;34m(self, timeout)\u001B[0m\n\u001B[1;32m    332\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:    \u001B[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001B[39;00m\n\u001B[1;32m    333\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m timeout \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m--> 334\u001B[0m         \u001B[43mwaiter\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43macquire\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    335\u001B[0m         gotit \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[1;32m    336\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "def read_json_files(my_dir_path):\n",
    "        data = pd.DataFrame()\n",
    "        for file in os.listdir(my_dir_path):\n",
    "            if file.endswith('.json'):\n",
    "                with open(os.path.join(my_dir_path, file), 'r') as f:\n",
    "                    my_data = [data['0'] for data in json.load(f).values()][1]\n",
    "                    data = pd.concat([data,  pd.DataFrame(my_data)], ignore_index=True, axis=0)\n",
    "        return data\n",
    "batch_size = 64\n",
    "epochs = 500\n",
    "\n",
    "final_file = 'monk3_models_configs_hist6.json'\n",
    "\n",
    "if not os.path.exists(final_file):\n",
    "    dir_path = \"Monk3/\"\n",
    "    \n",
    "    all_json_data = read_json_files(dir_path)\n",
    "    regularizations = all_json_data['regularization'].unique().tolist()\n",
    "    learning_rates = all_json_data['learning_rate'].unique().tolist()\n",
    "    learning_rates = set([value if 0.09 < value< 0.25 else 0.1 for value in learning_rates])\n",
    "    # momentums = all_json_data['momentum'].unique().tolist()\n",
    "    momentums = [0.1, 0.2, 0]\n",
    "    num_of_layers = [2]#all_json_data['num_layers'].unique().tolist()\n",
    "    num_of_units = set([unit1 for unit in all_json_data['num_of_units'] for unit1 in unit])\n",
    "    initializers = [\"uniform\", \"gaussian\"]\n",
    "    activations = [\"sigmoid\", 'tanh']\n",
    "    \n",
    "    myConfigurator = ConfiguratorGen(random=False, learning_rates=learning_rates, regularizations=regularizations,\n",
    "                                     loss_function=['mse'], optimizer=['sgd'],\n",
    "                                     activation_functions=activations,\n",
    "                                     number_of_units=num_of_units, number_of_layers=num_of_layers,\n",
    "                                     momentums=momentums, initializers=initializers,\n",
    "                                     input_shapes=training_data.shape,\n",
    "                                     verbose=False, nesterov=True,\n",
    "                                     callbacks=[\"earlystopping\"], output_activation='linear', show_line=False,\n",
    "                                     ).get_configs()\n",
    "    len(myConfigurator)\n",
    "    \n",
    "    configs=[]\n",
    "    if __name__ == '__main__':\n",
    "        configs.append(\n",
    "            parallel_hold_out(myConfigurator, training=training_data, training_target=training_labels, epochs=epochs,\n",
    "                              batch_size=batch_size, num_models=100, workers=4, number_of_initializations=3, return_models_history=True,\n",
    "                              ))\n",
    "    \n",
    "        configs = pd.DataFrame(configs)\n",
    "        # Save as json\n",
    "        configs.to_json(final_file)\n",
    "else: \n",
    "    with open(final_file, 'r') as f:\n",
    "        configs = [data['0'] for data in json.load(f).values()]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-08T14:06:24.056010Z",
     "start_time": "2024-01-08T14:06:08.998303Z"
    }
   },
   "id": "811d4687b8384299"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "my_configs = []\n",
    "for config in configs[1]:\n",
    "    config['callbacks'] = ['earlystopping_1e-4_50_False_True']\n",
    "# ea = EarlyStoppingCallback(restore_weights=True)\n",
    "if __name__ == '__main__':\n",
    "    # for config in configs[1]:\n",
    "    #     config['callbacks'] = [ea]\n",
    "    my_configs.append(\n",
    "        validate(configs[1], x=training_data, y_true=training_labels, epochs=epochs, return_models_history=True,\n",
    "                          batch_size=batch_size, max_configs=100, number_of_initializations=2, n_splits=4, parallel=False\n",
    "                          ))\n",
    "    \n",
    "    # my_configs.append(\n",
    "    #     hold_out(configs[1], training=training_data, training_target=training_labels, epochs=epochs, return_models_history=True,\n",
    "    #                       batch_size=batch_size, num_models=100, number_of_initializations=2,\n",
    "    #                       ))\n",
    "\n",
    "configs=my_configs[0]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-08T14:06:24.063094Z",
     "start_time": "2024-01-08T14:06:24.058517Z"
    }
   },
   "id": "d1e7d636a8ba4ab"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "models = []\n",
    "old_histories = configs[0]\n",
    "configs=configs[1]\n",
    "with tqdm(total=len(configs)) as pbar:\n",
    "    for old_hist, config in zip(old_histories, configs):\n",
    "        model = Composer(config=config).compose()\n",
    "        model.train(inputs=training_data, input_label=training_labels, epochs=epochs, batch_size=batch_size, name=config['model_name'], disable_line=True)\n",
    "        test_val = model.evaluate(input=test_data, input_label=test_labels)\n",
    "        models.append((model.get_last()['mse'], np.std(np.array(model.history['mse'])), model.get_last()['binary_accuracy'], test_val[0], test_val[1], model.curr_epoch, old_hist['binary_accuracy'][-1],  old_hist['val_binary_accuracy'][-1], old_hist['mse'],  old_hist['val_mse'], model.history['mse'], Composer(config=config).compose(), config, config['num_layers'], config['num_of_units'], config['model_name']))\n",
    "        pbar.update(1)\n",
    "\n",
    "# Convert the list of tuples to a DataFrame with one column for each element in the tuple\n",
    "df = pd.DataFrame(models, columns=['Score', 'History_Std', 'Accuracy', 'Test_Score', 'Test_Accuracy', 'Trained_Epochs', 'Old_Accuracy', 'Old_Accuracy_val', 'Old_History', 'Old_History_val', 'History', 'Model', 'Config', 'Num_Layers', 'Num_of_Units', 'Name'])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-01-08T14:06:24.060837Z"
    }
   },
   "id": "7b144053f7348102"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Sort the DataFrame by the first element in the tuple (column 'Value')\n",
    "\n",
    "df_sorted = df.sort_values(by=['Num_Layers', 'Score', 'Test_Score', 'History_Std'])\n",
    "df_sorted = df_sorted[df_sorted['Accuracy'] >= 0.95] \n",
    "df_sorted = df_sorted[df_sorted['Test_Accuracy'] >= 0.96]\n",
    "df_sorted = df_sorted[df_sorted['Old_Accuracy_val'] >= 0.97]\n",
    "# df_sorted = df_sorted[df_sorted['History_Std'] <= 0.1] \n",
    "# df_sorted = df_sorted[df_sorted['Num_Layers'] <= 1]\n",
    "# df_sorted['Num_of_Units'] = [value[0] for value in df_sorted['Num_of_Units']]\n",
    "# df_sorted = df_sorted[df_sorted['Num_of_Units'] == 4]\n",
    "histories = {row[0]: row[1] for row in df_sorted[['Name', 'History']].values}\n",
    "old_histories = {row[0]: row[1] for row in df_sorted[['Name', 'Old_History']].values}\n",
    "old_histories_val = {row[0]: row[1] for row in df_sorted[['Name', 'Old_History_val']].values}\n",
    "df_sorted"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-08T14:06:24.064818Z",
     "start_time": "2024-01-08T14:06:24.063813Z"
    }
   },
   "id": "b0205ce48eb9dc26"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plot_history(old_histories_val)\n",
    "plot_history({list(histories)[0]: list(histories.values())[0]})\n",
    "plot_history({'ModelHoldOutMee': list(old_histories.values())[0], 'ModelHoldOutMeeVal': list(old_histories_val.values())[0]})\n",
    "# plot_history({list(histories)[1]: list(histories.values())[1]})\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-08T14:06:24.084073Z",
     "start_time": "2024-01-08T14:06:24.066769Z"
    }
   },
   "id": "8599132fc0a25571"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def find_least_difference_row(my_df):\n",
    "    min_diff = float('inf')\n",
    "    selected_row = None\n",
    "\n",
    "    for index, row in my_df.iterrows():\n",
    "        array1 = np.array(row['History'])\n",
    "        differences1 =  (np.diff(array1) - np.mean(array1)) /np.mean(array1)\n",
    "        min_consecutive_difference = np.min(differences1)\n",
    "\n",
    "        if min_consecutive_difference < min_diff:\n",
    "            min_diff = min_consecutive_difference\n",
    "            selected_row = row\n",
    "\n",
    "    return selected_row\n",
    "\n",
    "result_row = find_least_difference_row(df_sorted)\n",
    "# Pivot the DataFrame using 'Unnamed: 0' as both index and columns\n",
    "print(result_row)\n",
    "plot_history({result_row['Name']: result_row['History']}, fig_size=(10,8))\n",
    "plot_history({'KFoldTrain'+result_row[\"Name\"]: -np.sort(-np.array(result_row['Old_History'])), 'KFoldTrainVal'+result_row[\"Name\"]: -np.sort(-np.array(result_row['Old_History_val']))}, fig_size=(10,8))\n",
    "plot_history({result_row[\"Name\"]: result_row['History'], 'KFoldTrain'+result_row[\"Name\"]: result_row['Old_History'], 'KFoldTrainVal'+result_row[\"Name\"]: result_row['Old_History_val']}, fig_size=(10,8))\n",
    "#Df sorted to pickle \n",
    "result_row.to_csv('Monk3_train.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-01-08T14:06:24.069633Z"
    }
   },
   "id": "df89379b1f6c8b6d"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def plot_history2(name, lines: dict, fig_size=(10, 6)):\n",
    "    plt.figure(figsize=fig_size)\n",
    "    for elem in lines:\n",
    "        plt.plot(lines[elem], label=elem)\n",
    "    plt.legend(fontsize=12)\n",
    "    plt.savefig(name+'.eps', format='eps')\n",
    "    plt.savefig(name+'.png', format='png')\n",
    "    \n",
    "plot_history2(name='Monk3_train', lines={result_row[\"Name\"]: result_row['History']}, fig_size=(10,8))\n",
    "plot_history2(name='Monk3_KFold', lines={'KFoldTrain'+result_row[\"Name\"]: -np.sort(-np.array(result_row['Old_History'])), 'KFoldTrainVal'+result_row[\"Name\"]: -np.sort(-np.array(result_row['Old_History_val']))}, fig_size=(10,8))\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-01-08T14:06:24.072609Z"
    }
   },
   "id": "5af4e5a0f1fedea8",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "{'regularization': 1e-07, 'learning_rate': 0.22, 'loss_function': 'mse', 'activation_functions': ['tanh'], 'output_activation': 'sigmoid', 'num_of_units': [3], 'num_layers': 1, 'momentum': 0.1, 'optimizer': 'sgd', 'initializers': 'uniform', 'nesterov': True, 'input_shape': [122, 17], 'callbacks': ['earlystopping_1e-4_50_False_True'], 'verbose': False, 'outputs': 1, 'model_name': 'Model2427'}"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3874c817917f92e2"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
